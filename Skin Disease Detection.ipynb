{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.layers import Dense, Input,Dropout,GlobalAveragePooling2D,Input,Conv2D, BatchNormalization, Activation, MaxPooling2D,Flatten\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'Dermnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset paths\n",
    "dataset_train_path = os.path.join(dataset_path,'train')\n",
    "dataset_test_path = os.path.join(dataset_path,'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 files belonging to 23 classes.\n",
      "Found 378 files belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "# train and test dataset\n",
    "dataset_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    " dataset_train_path,\n",
    "  batch_size=32)\n",
    "\n",
    "dataset_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  dataset_test_path,\n",
    "  batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acne and Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', 'Bullous Disease Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', 'Hair Loss Photos Alopecia and other Hair Diseases', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', 'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Nail Fungus and other Nail Disease', 'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Scabies Lyme Disease and other Infestations and Bites', 'Seborrheic Keratoses and other Benign Tumors', 'Systemic Disease', 'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', 'Warts Molluscum and other Viral Infections']\n"
     ]
    }
   ],
   "source": [
    "#labels\n",
    "dataset_name=dataset_train\n",
    "class_names=dataset_train.class_names\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training images\n",
    "\n",
    "trn_images = []\n",
    "trn_labels = []\n",
    "for root, directories, files in os.walk(dataset_train_path):\n",
    "    for file in files:\n",
    "        image = cv2.imread(os.path.join(root, file))\n",
    "        \n",
    "        #check if image is loaded successfully\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            trn_images.append(image)\n",
    "            trn_labels.append(root.split('/')[-1])\n",
    "        else:\n",
    "            print(f\"Failed to load image: {os.path.join(root, file)}\")\n",
    "        \n",
    "\n",
    "\n",
    "#Loading test images\n",
    "tst_images = []\n",
    "tst_labels = []\n",
    "\n",
    "for label in os.listdir(dataset_test_path):\n",
    "   for file in files:\n",
    "       image = cv2.imread(os.path.join(root, file))\n",
    "       \n",
    "       if image is not None:\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        tst_images.append(image)\n",
    "        tst_labels.append(root.split('/')[-1])\n",
    "       else:\n",
    "          print(f\"Failed to load image: {os.path.join(root, file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 images belonging to 23 classes.\n",
      "Found 378 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#ImageDataGenerator instance\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#data generators for training and testing\n",
    "trn_generator = datagen.flow_from_directory(dataset_train_path,\n",
    "                                            target_size=(224,224),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "tst_generator = datagen.flow_from_directory(\n",
    "    dataset_test_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the data\n",
    "def image_generator(images):\n",
    "    for image in images:\n",
    "        yield image.astype('float32') / 255.0\n",
    "trn_generator = image_generator(trn_images)\n",
    "tst_generator = image_generator(tst_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conerting lists to Numpy arrays\n",
    "trn_images = np.array(trn_images)\n",
    "tst_images = np.array(tst_images)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Processing training images in batches\n",
    "for i in range(0, len(trn_images), batch_size):\n",
    "    batch = trn_images[i:i + batch_size].astype('float32') / 255.0\n",
    "    for j in range(len(batch)):\n",
    "        batch[j] = cv2.GaussianBlur(batch[j], (5,5), sigmaX=0)\n",
    "    \n",
    "    trn_images[i:i + batch_size] = batch\n",
    "\n",
    "# Processing testing images in batches\n",
    "for i in range(0, len(tst_images), batch_size):\n",
    "    batch = tst_images[i:i + batch_size].astype('float32') / 255.0\n",
    "    for j in range(len(batch)):\n",
    "        batch[j] = cv2.GaussianBlur(batch[j], (5,5), sigmaX=0)\n",
    "\n",
    "    tst_images[i:i + batch_size] = batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tekkz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\Tekkz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Resizing\n",
    "trn_images_resized = [cv2.resize(image, (64, 64)) for image in trn_images]\n",
    "tst_images_resized = [cv2.resize(image, (64,64))for image in tst_images]\n",
    "\n",
    "#Reshaping the resized images\n",
    "trn_images_flat = np.array([image.flatten() for image in trn_images_resized])\n",
    "tst_images_flat = np.array([image.flatten() for image in tst_images_resized])\n",
    "\n",
    "#Segmentation with K-Means clustering\n",
    "trn_images =trn_images.reshape((trn_images.shape[0], -1))\n",
    "tst_images = tst_images.reshape((tst_images.shape[0], -1))\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(trn_images)\n",
    "trn_labels = kmeans.predict(trn_images)\n",
    "tst_labels = kmeans.predict(tst_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current shape of image array (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Current shape of image array\", image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLCM Feature extraction\n",
    "trn_features = []\n",
    "trn_images = []\n",
    "tst_images = []\n",
    "\n",
    "for image in trn_images:\n",
    "    if len(image.shape) == 1:\n",
    "        side_length = int(np.sqrt(len(image)))\n",
    "        # Checking if reshaped dimensions are valid\n",
    "        if side_length * side_length == len(image):\n",
    "            image = image.reshape((side_length, side_length))\n",
    "        else:\n",
    "            print(f\"Skipping image with invalid reshape dimensions: {image.shape}\")\n",
    "            continue\n",
    "    elif len(image.shape) == 2:\n",
    "        features = graycomatrix(image, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "        trn_features.append(features.flatten())\n",
    "    else:\n",
    "        print(f\"Skipping image with shape {image.shape}. It must be a 2D array.\")\n",
    "\n",
    "tst_features = []\n",
    "\n",
    "for image in tst_images:\n",
    "    print(f\"Image shape before graycomatrix: {image.shape}\")\n",
    "    if len(image.shape) == 1:\n",
    "        side_length = int(np.sqrt(len(image)))\n",
    "        # Checking if reshaped dimensions are valid\n",
    "        if side_length * side_length == len(image):\n",
    "            image = image.reshape((side_length, side_length))\n",
    "        else:\n",
    "            print(f\"Skipping testing image with invalid reshape dimensions: {image.shape}\")\n",
    "            continue\n",
    "    elif len(image.shape) == 2:\n",
    "        features = graycomatrix(image, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "        tst_features.append(features.flatten())\n",
    "    else:\n",
    "        print(f\"Skipping testing image with shape {image.shape}. It must be a 2D array.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting labels to categorical\n",
    "trn_labels = to_categorical(trn_labels)\n",
    "tst_labels = to_categorical(tst_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "num_classes = 23\n",
    "\n",
    "#base pre-trained model\n",
    "base_model = InceptionResNetV2(include_top=False, weights='imagenet',input_shape=(224,224,3))\n",
    "\n",
    "#Freezing the base model weights\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 images belonging to 23 classes.\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 53s 9s/step - loss: 3.1976 - accuracy: 0.0901\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 35s 8s/step - loss: 2.4702 - accuracy: 0.3430\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 37s 9s/step - loss: 1.6301 - accuracy: 0.5872\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 37s 8s/step - loss: 0.9317 - accuracy: 0.7674\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 35s 8s/step - loss: 0.4656 - accuracy: 0.8953\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 34s 8s/step - loss: 0.2601 - accuracy: 0.9244\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 34s 8s/step - loss: 0.1623 - accuracy: 0.9448\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 35s 8s/step - loss: 0.1414 - accuracy: 0.9680\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 35s 10s/step - loss: 0.1126 - accuracy: 0.9535\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 34s 8s/step - loss: 0.1111 - accuracy: 0.9564\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 34s 10s/step - loss: 0.1019 - accuracy: 0.9448\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 35s 8s/step - loss: 0.0865 - accuracy: 0.9535\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 34s 10s/step - loss: 0.0756 - accuracy: 0.9593\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 35s 8s/step - loss: 0.0831 - accuracy: 0.9419\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 34s 10s/step - loss: 0.0699 - accuracy: 0.9506\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 35s 10s/step - loss: 0.0814 - accuracy: 0.9535\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 34s 10s/step - loss: 0.0715 - accuracy: 0.9622\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 36s 9s/step - loss: 0.0797 - accuracy: 0.9535\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 36s 10s/step - loss: 0.0815 - accuracy: 0.9477\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 35s 8s/step - loss: 0.0696 - accuracy: 0.9506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x123a7a4cc10>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),  \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Assuming num_classes is the number of output classes\n",
    "])\n",
    "\n",
    "\n",
    "trn_generator = datagen.flow_from_directory(\n",
    "    dataset_train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "#Unfreezing the last few layers\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Now, you can train the model on your dataset\n",
    "model.fit(trn_generator, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Capsnet model\n",
    "from __future__ import division, print_function, unicode_literals #support both python 2 & 3\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tekkz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\client\\session.py:1793: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 images belonging to 23 classes.\n",
      "Found 378 images belonging to 23 classes.\n",
      "Number of training samples: 4\n",
      "Number of training labels: 344\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 301s 65s/step - loss: 2187.3459 - accuracy: 0.0349\n",
      "Epoch 2/10\n",
      "1/4 [======>.......................] - ETA: 4:17 - loss: 4202.2598 - accuracy: 0.0200"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "trn_generator = datagen.flow_from_directory(\n",
    "    dataset_train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "tst_generator = datagen.flow_from_directory(\n",
    "    dataset_test_path,\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "\n",
    "# Convert trn_labels to one-hot encoding if it's not already\n",
    "trn_labels_one_hot = tf.keras.utils.to_categorical(trn_labels, num_classes=23)\n",
    "\n",
    "\n",
    "print(\"Number of training samples:\", len(trn_generator))\n",
    "print(\"Number of training labels:\", len(trn_labels_one_hot))\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add a Primary Capsule Layer\n",
    "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(layers.Reshape((-1, 8)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Reshape((-1, 32, 8)))\n",
    "\n",
    "# Add a Digit Capsule Layer\n",
    "model.add(layers.Conv2D(10, (1, 1), activation='sigmoid'))\n",
    "model.add(layers.Reshape((-1, 10, 8)))\n",
    "\n",
    "# Add a fully connected layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(23, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(trn_generator, epochs=10)\n",
    "\n",
    "tst_images = tst_images.reshape((-1, 224, 224, 3))\n",
    "tst_labels_one_hot = tf.keras.utils.to_categorical(tst_labels, num_classes=23)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(tst_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mICS Project II\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject II\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSkin disease\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"D:\\Documents\\ICS Project II\\Project II\\Skin disease\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
