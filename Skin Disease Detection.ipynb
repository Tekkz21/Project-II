{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.layers import Dense, Input,Dropout,GlobalAveragePooling2D\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'D:\\Documents\\ICS Project II\\Datasets\\Dermnet'\n",
    "\n",
    "# Load images \n",
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset paths\n",
    "dataset_train_path = os.path.join(dataset_path,'train')\n",
    "dataset_test_path = os.path.join(dataset_path,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15557 files belonging to 23 classes.\n",
      "Found 4002 files belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "# train and test dataset\n",
    "dataset_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  dataset_train_path,\n",
    "  batch_size=128)\n",
    "\n",
    "dataset_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  dataset_test_path,\n",
    "  batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acne and Rosacea Photos', 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions', 'Atopic Dermatitis Photos', 'Bullous Disease Photos', 'Cellulitis Impetigo and other Bacterial Infections', 'Eczema Photos', 'Exanthems and Drug Eruptions', 'Hair Loss Photos Alopecia and other Hair Diseases', 'Herpes HPV and other STDs Photos', 'Light Diseases and Disorders of Pigmentation', 'Lupus and other Connective Tissue diseases', 'Melanoma Skin Cancer Nevi and Moles', 'Nail Fungus and other Nail Disease', 'Poison Ivy Photos and other Contact Dermatitis', 'Psoriasis pictures Lichen Planus and related diseases', 'Scabies Lyme Disease and other Infestations and Bites', 'Seborrheic Keratoses and other Benign Tumors', 'Systemic Disease', 'Tinea Ringworm Candidiasis and other Fungal Infections', 'Urticaria Hives', 'Vascular Tumors', 'Vasculitis Photos', 'Warts Molluscum and other Viral Infections']\n"
     ]
    }
   ],
   "source": [
    "#labels\n",
    "dataset_name=dataset_train\n",
    "class_names=dataset_train.class_names\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image resizing & data standardization\n",
    "image_size=(246, 246)\n",
    "\n",
    "dataset_train = dataset_train.map (lambda image, label: (tf.image.resize(image, image_size),label))\n",
    "dataset_test = dataset_test.map (lambda image, label:(tf.image.resize(image, image_size), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading training images\n",
    "\n",
    "trn_images = []\n",
    "trn_labels = []\n",
    "for label in os.listdir(dataset_train_path):\n",
    "    label_dir = os.path.join(dataset_train_path, label)\n",
    "    for image_file in os.listdir(label_dir):\n",
    "        image_path = os.path.join(label_dir, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        trn_images.append(image)\n",
    "        trn_labels.append(label)\n",
    "\n",
    "#lists->numpy arrays\n",
    "trn_images = np.array(trn_images)\n",
    "trn_labels = np.array(trn_labels)\n",
    "\n",
    "#Loading test images\n",
    "\n",
    "tst_images = []\n",
    "tst_labels = []\n",
    "for label in os.listdir(dataset_test_path):\n",
    "    label_dir = os.path.join(dataset_test_path, label)\n",
    "    for image_file in os.listdir(label_dir):\n",
    "        image_path = os.path.join(label_dir, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        tst_images.append(image)\n",
    "        tst_labels.append(label)\n",
    "\n",
    "# Lists -> numpy arrays\n",
    "tst_images = np.array(tst_images)\n",
    "tst_labels = np.array(tst_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening training images\n",
    "\n",
    "trn_images_flat = trn_images.reshape(trn_images.shape[0], -1)\n",
    "\n",
    "#KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(trn_images_flat)\n",
    "\n",
    "#cluster labels\n",
    "trn_labels_segmented = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLCM Feature extraction\n",
    "def clc_glcm_features(images):\n",
    "    glcm_features = []\n",
    "\n",
    "#feature extraction for training & testing\n",
    "\n",
    "    for image in trn_images:\n",
    "      glcm = graycomatrix(image, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "      contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "      dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "      homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "      energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "      correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "      glcm_features.append([contrast, dissimilarity, homogeneity, energy, correlation])\n",
    "\n",
    "    return np.array(glcm_features)\n",
    "\n",
    "\n",
    "\n",
    "# Feature vectors->numpy arrays\n",
    "trn_glcm_features = clc_glcm_features(trn_images)\n",
    "tst_glcm_features = clc_glcm_features(tst_images)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 29.1 GiB for an array with shape (331, 10528, 1120) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\ICS Project II\\Project II\\Skin Disease Detection.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/ICS%20Project%20II/Project%20II/Skin%20Disease%20Detection.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#Repeat the features to form an image with (224, 224, 3)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/ICS%20Project%20II/Project%20II/Skin%20Disease%20Detection.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m trn_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(reshaped_trn_features, \u001b[39m224\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/ICS%20Project%20II/Project%20II/Skin%20Disease%20Detection.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m trn_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrepeat(trn_images, \u001b[39m224\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/ICS%20Project%20II/Project%20II/Skin%20Disease%20Detection.ipynb#X25sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m trn_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(trn_images, \u001b[39m3\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/ICS%20Project%20II/Project%20II/Skin%20Disease%20Detection.ipynb#X25sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#inceptionresnetV2\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tekkz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:466\u001b[0m, in \u001b[0;36mrepeat\u001b[1;34m(a, repeats, axis)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_repeat_dispatcher)\n\u001b[0;32m    424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepeat\u001b[39m(a, repeats, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    425\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39m    Repeat each element of an array after themselves\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mrepeat\u001b[39;49m\u001b[39m'\u001b[39;49m, repeats, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\Tekkz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 29.1 GiB for an array with shape (331, 10528, 1120) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Preprocessing feature vectors\n",
    "trn_features = trn_glcm_features/np.max(trn_glcm_features)\n",
    "tst_features = tst_glcm_features/np.max(tst_glcm_features)\n",
    "\n",
    "\n",
    "reshaped_trn_features = np.reshape(trn_features, (331,47,5))\n",
    "\n",
    "#Repeat the features to form an image with (224, 224, 3)\n",
    "trn_images = np.repeat(reshaped_trn_features, 224, axis=1)\n",
    "trn_images = np.repeat(trn_images, 224, axis=2)\n",
    "trn_images = np.repeat(trn_images, 3, axis=3)\n",
    "\n",
    "\n",
    "#inceptionresnetV2\n",
    "inception_model = InceptionResNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224, 3)))\n",
    "\n",
    "# Global avrg pooling & dense layer for classification\n",
    "x = inception_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "#Identify unique classes\n",
    "unique_classes = np.unique(trn_images)\n",
    "num_classes = len(unique_classes)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#Model\n",
    "model = Model(inputs=inception_model.input, outputs=predictions)\n",
    "\n",
    "#Freezing layers of inception model\n",
    "for layer in inception_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Comp\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "trn_labels_encoded = label_encoder.fit_transform(trn_labels)\n",
    "\n",
    "#Conversion to one-hot encoding\n",
    "trn_labels_one_hot = to_categorical(trn_labels_encoded)\n",
    "\n",
    "#Train\n",
    "model.fit(reshaped_trn_features, trn_labels_one_hot, batch_size=64, epochs=50, validation_split=0.2, callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "#Test\n",
    "pred = model.predict(tst_features)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "\n",
    "#Acc and Precision\n",
    "accuracy = accuracy_score(tst_labels, pred_labels)\n",
    "precision = precision_score(tst_labels, pred_labels, average='weighted')\n",
    "\n",
    "\n",
    "#inception_features = inception_model.predict(trn_features)\n",
    "#inception_features_test = inception_model.predict(tst_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77785\n",
      "(15557, 5)\n"
     ]
    }
   ],
   "source": [
    "print(trn_features.size)\n",
    "print(trn_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CapsNet model\n",
    "cpsle_model = Sequential()\n",
    "cpsle_model.add(Dense(64, activation='relu', input_shape=(trn_features.shape[1],)))\n",
    "cpsle_model.add(Dropout(0.5))\n",
    "cpsle_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compilation and training\n",
    "cpsle_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cpsle_model.fit(inception_features, trn_labels, epochs = 100 , batch_size =32)\n",
    "\n",
    "#Model evaluation\n",
    "inception_predictions = cpsle_model.predict_classes(inception_features_test)\n",
    "accuracy = accuracy_score(tst_labels, inception_predictions)\n",
    "precision = precision_score(tst_labels, inception_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: {:.2f}%\".format(precision * 100))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
